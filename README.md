# Ultra Tic-Tac-Toe AlphaZero

AlphaZero ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•œ Ultimate Tic-Tac-Toe AI í•™ìŠµ í”„ë¡œì íŠ¸

## í”„ë¡œì íŠ¸ êµ¬ì¡°

```
ultra-tictacto/
â”œâ”€â”€ ai/                    # AI ê´€ë ¨ ëª¨ë“ˆ
â”‚   â”œâ”€â”€ agent.py          # MCTS Agent ë° AlphaZero Agent
â”‚   â”œâ”€â”€ network.py        # Neural Network (ResNet)
â”‚   â”œâ”€â”€ trainer.py        # Self-play ë° í•™ìŠµ ë¡œì§
â”‚   â””â”€â”€ env.py            # í™˜ê²½ ì¸í„°í˜ì´ìŠ¤
â”œâ”€â”€ game/                  # ê²Œì„ ë¡œì§
â”‚   â””â”€â”€ board.py          # Ultimate Tic-Tac-Toe ë³´ë“œ
â”œâ”€â”€ ui/                    # UI ê´€ë ¨
â”‚   â””â”€â”€ game_ui.py        # Pygame UI
â”œâ”€â”€ config.py             # ì„¤ì • íŒŒì¼ (GPU ìµœì í™” í¬í•¨)
â”œâ”€â”€ train.py              # í•™ìŠµ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ main.py               # ê²Œì„ ì‹¤í–‰
```

## ì„¤ì¹˜ ë°©ë²•

1. **ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”**
```bash
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# .venv\Scripts\activate   # Windows
```

2. **ì˜ì¡´ì„± ì„¤ì¹˜**
```bash
pip install -r requirements.txt
```

## ì‚¬ìš©ë²•

### í•™ìŠµ ì‹¤í–‰

**ìë™ ì„¤ì • (GPU ê°ì§€)**
```bash
python train.py
```

**ì»¤ìŠ¤í…€ ì„¤ì •**
```python
from config import Config, get_gpu_optimized_config, get_cpu_config
from train import train_alphazero

# GPU ìµœì í™” ì„¤ì • (RTX 5090 ë“±)
config = get_gpu_optimized_config()
train_alphazero(config)

# CPU ì„¤ì •
config = get_cpu_config()
train_alphazero(config)
```

### ê²Œì„ í”Œë ˆì´

```bash
python main.py
```

## ì„¤ì • (config.py)

### NetworkConfig
- `num_res_blocks`: ResNet ë¸”ë¡ ê°œìˆ˜ (ê¸°ë³¸: 10)
- `num_channels`: ì±„ë„ ìˆ˜ (ê¸°ë³¸: 256)

### TrainingConfig
- `num_iterations`: í•™ìŠµ ë°˜ë³µ íšŸìˆ˜
- `batch_size`: ë°°ì¹˜ ì‚¬ì´ì¦ˆ (GPU: 1024, CPU: 32)
- `num_simulations`: MCTS ì‹œë®¬ë ˆì´ì…˜ íšŸìˆ˜
- `use_amp`: Mixed Precision Training ì‚¬ìš© ì—¬ë¶€

### ì£¼ìš” íŠ¹ì§•

1. **6ì±„ë„ ì…ë ¥**
   - Player 1 positions
   - Player 2 positions
   - Current player indicator
   - Completed boards (Player 1)
   - Completed boards (Player 2)
   - Draw boards

2. **GPU ìµœì í™”**
   - Mixed Precision Training (AMP)
   - Large batch size support (1024)
   - CUDA/MPS/CPU ìë™ ê°ì§€
   - **ë°°ì¹˜ MCTS**: GPU í™œìš©ì„ ê·¹ëŒ€í™”í•˜ëŠ” ë°°ì¹˜ í‰ê°€
   - **Virtual Loss**: ë³‘ë ¬ ì‹œë®¬ë ˆì´ì…˜ ì§€ì›

3. **AlphaZero êµ¬í˜„**
   - MCTS with neural network guidance
   - Self-play data generation
   - Policy + Value dual-head network

### ğŸš€ ì„±ëŠ¥ ìµœì í™” (v2.0)

#### ë°°ì¹˜ MCTS
ê¸°ì¡´ ìˆœì°¨ MCTSì˜ GPU í™œìš©ë„ê°€ ë‚®ì€ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë°°ì¹˜ í‰ê°€ë¥¼ ë„ì…í–ˆìŠµë‹ˆë‹¤.

**ê°œì„  ì‚¬í•­:**
- **ë°°ì¹˜ í¬ê¸°**: 8ê°œì˜ MCTS ì‹œë®¬ë ˆì´ì…˜ì„ ë™ì‹œì— í‰ê°€
- **Virtual Loss**: ë³‘ë ¬ ì‹œë®¬ë ˆì´ì…˜ ì¤‘ íŠ¸ë¦¬ íƒìƒ‰ ì¶©ëŒ ë°©ì§€
- **GPU ì²˜ë¦¬ëŸ‰**: ë„¤íŠ¸ì›Œí¬ í˜¸ì¶œ íšŸìˆ˜ ê°ì†Œë¡œ GPU í™œìš©ë„ í–¥ìƒ

**ì‚¬ìš©ë²•:**
```python
from ai.agent import AlphaZeroAgent

# ë°°ì¹˜ í¬ê¸° ì„¤ì • (ê¸°ë³¸ê°’: 8)
agent = AlphaZeroAgent(
    network=network,
    num_simulations=100,
    batch_size=8  # GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì ˆ
)
```

**ì˜ˆìƒ ì„±ëŠ¥ í–¥ìƒ:**
- Self-play ì†ë„: ~2-3x í–¥ìƒ (GPU ì‚¬ìš© ì‹œ)
- GPU í™œìš©ë¥ : 20-30% â†’ 60-80%

## ë„¤íŠ¸ì›Œí¬ ì•„í‚¤í…ì²˜

- **Input**: 6 channels Ã— 9Ã—9 board
- **Backbone**: ResNet (10 blocks, 256 channels)
- **Policy Head**: 81 output (ëª¨ë“  ê°€ëŠ¥í•œ ìœ„ì¹˜)
- **Value Head**: 1 output (ìŠ¹ë¥  ì˜ˆì¸¡, -1 ~ 1)
- **Parameters**: ~11.8M (256ch, 10 blocks)

## í”„ë¡œì íŠ¸ íŒ¨í‚¤ì§•

```bash
./package.sh
```

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ”:
- `requirements.txt` ìë™ ìƒì„±
- `.venv`, `__pycache__`, `.git` ë“± ì œì™¸
- íƒ€ì„ìŠ¤íƒ¬í”„ê°€ í¬í•¨ëœ tar.gz íŒŒì¼ ìƒì„±

## ë¼ì´ì„¼ìŠ¤

MIT License
# ultra-tictactoe
# ultra-tictactoe
